{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch, random, math\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tnrange\n",
    "from time import time\n",
    "from torch import nn\n",
    "from torchtext import data\n",
    "from torch.autograd import Variable\n",
    "from iseq2seq.utils import load_anki_dataset, write_training_log\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "801"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "data_path = 'data/dataset.pkl'\n",
    "\n",
    "ds_train, ds_test, ds_val, ES, EN = load_anki_dataset(data_path)\n",
    "es_dict = {v:k for k,v in ES.vocab.stoi.items()}\n",
    "en_dict = {v:k for k,v in EN.vocab.stoi.items()}\n",
    "\n",
    "train_buckets = data.BucketIterator(ds_train, batch_size,\n",
    "    sort_key=lambda x: data.interleave_keys(len(x.es), len(x.en)))\n",
    "test_buckets = data.BucketIterator(ds_test, batch_size,\n",
    "    sort_key=lambda x: data.interleave_keys(len(x.es), len(x.en)))\n",
    "val_buckets = data.BucketIterator(ds_val, batch_size,\n",
    "    sort_key=lambda x: data.interleave_keys(len(x.es), len(x.en)))\n",
    "train_iter = iter(train_buckets)\n",
    "test_iter = iter(test_buckets)\n",
    "val_iter = iter(val_buckets)\n",
    "epoch_batchs_train = math.ceil(len(train_buckets.dataset.examples) / train_buckets.batch_size)\n",
    "epoch_batchs_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_max_length = 0\n",
    "\n",
    "for ex in train_buckets.dataset.examples:\n",
    "    train_max_length = max(train_max_length, len(ex.en))\n",
    "    \n",
    "train_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SOS_token = EN.vocab.stoi['<sos>']\n",
    "EOS_token = EN.vocab.stoi['<eos>']\n",
    "SOS_token, EOS_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar Embeddings (GloVe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spanish embeddings: torch.Size([10264, 50]) found: 10135\n",
      "English embeddings: torch.Size([6548, 300]) found: 4574\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "spacy_es = spacy.load('es')\n",
    "spacy_en = spacy.load('en')\n",
    "\n",
    "def create_emb(lang_model, vocab, dim_vec):\n",
    "    vocab_size = len(vocab.itos)\n",
    "    emb = np.zeros((vocab_size, dim_vec))\n",
    "    found = 0\n",
    "\n",
    "    for i, word in enumerate(vocab.itos):\n",
    "        w = lang_model(word)\n",
    "        if w.has_vector:\n",
    "            emb[i] = lang_model(word).vector\n",
    "            found += 1\n",
    "        else:\n",
    "            # Si no se encuentra una palabra en los embeddings\n",
    "            # entrenados, se usa un vector random.\n",
    "            emb[i] = np.random.normal(scale=0.6, size=(dim_vec,))\n",
    "\n",
    "    return torch.from_numpy(emb), found\n",
    "\n",
    "emb_es, found_es = create_emb(spacy_es, ES.vocab, 50)\n",
    "print('Spanish embeddings:', emb_es.shape, 'found:', found_es)\n",
    "emb_en, found_en = create_emb(spacy_en, EN.vocab, 300)\n",
    "print('English embeddings:', emb_en.shape, 'found:', found_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_emb(emb_mat):\n",
    "    output_size, emb_size = emb_mat.size()\n",
    "    emb = nn.Embedding(output_size, emb_size)\n",
    "    emb.load_state_dict({'weight': emb_mat})\n",
    "\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1, bidirectional=False,\n",
    "                 embedding_dropout=0.1, rnn_dropout=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        self.embedding_dropout = embedding_dropout\n",
    "        self.rnn_dropout = rnn_dropout\n",
    "        \n",
    "        # Layers\n",
    "        self.embedding = load_emb(emb_es)\n",
    "        self.embedding_dropout = nn.Dropout(embedding_dropout)\n",
    "        self.lineal = nn.Linear(50, hidden_size) # 50 word_vec spanish\n",
    "        self.rnn = nn.GRU(hidden_size, hidden_size, num_layers=n_layers,\n",
    "                          bidirectional=bidirectional, dropout=rnn_dropout)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        embs = self.embedding(input)\n",
    "        embs = self.embedding_dropout(embs)\n",
    "        embs = self.lineal(embs)\n",
    "        output, hidden = self.rnn(embs, hidden)\n",
    "        if self.bidirectional:\n",
    "            # En caso el encoder sea bidireccional, se suman los outputs\n",
    "            # en vez de concatenarlos.\n",
    "            output = output[:, :, :self.hidden_size] + output[:, : ,self.hidden_size:]\n",
    "        \n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # metodos definidos en https://arxiv.org/pdf/1508.04025.pdf\n",
    "        assert method in ('dot', 'general', 'concat'), 'invalid attention method'\n",
    "        \n",
    "        # Layers\n",
    "        if self.method == 'general':\n",
    "            self.att = nn.Linear(self.hidden_size, hidden_size)\n",
    "\n",
    "        elif self.method == 'concat':\n",
    "            self.att = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.v = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        max_len = encoder_outputs.size(0)\n",
    "        this_batch_size = encoder_outputs.size(1)\n",
    "\n",
    "        # Se inicializa las energias de atencion y se calculan en cada elemento del batch\n",
    "        att_energies = Variable(torch.zeros(this_batch_size, max_len)).cuda()\n",
    "\n",
    "        for b in range(this_batch_size): # por cada elemento b del batch\n",
    "            for i in range(max_len): # por cada paso i de la secuencia\n",
    "                att_energies[b, i] = self.score(hidden[:, b].squeeze(0),\n",
    "                                                encoder_outputs[i, b])\n",
    "\n",
    "        # Se normalizan los pesos entre 0 y 1\n",
    "        return F.softmax(att_energies).unsqueeze(1)\n",
    "    \n",
    "    def score(self, hidden, encoder_output):\n",
    "        if self.method == 'dot':\n",
    "            energy = hidden.dot(encoder_output)\n",
    "            return energy\n",
    "        \n",
    "        elif self.method == 'general':\n",
    "            energy = self.att(encoder_output)\n",
    "            energy = hidden.dot(energy)\n",
    "            return energy\n",
    "        \n",
    "        elif self.method == 'concat':\n",
    "            energy = self.att(torch.cat((hidden, encoder_output), 1))\n",
    "            energy = self.v.dot(energy)\n",
    "            return energy\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, output_size, hidden_size, n_layers=1,\n",
    "                 att_method='general', embedding_dropout=0.1, rnn_dropout=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.att_method = att_method\n",
    "        self.embedding_dropout = embedding_dropout\n",
    "        self.rnn_dropout = rnn_dropout\n",
    "\n",
    "        # Layers\n",
    "        self.embedding = load_emb(emb_en)\n",
    "        self.embedding_dropout = nn.Dropout(embedding_dropout)\n",
    "        self.rnn = nn.GRU(hidden_size, hidden_size, n_layers, dropout=rnn_dropout)\n",
    "        self.attention = Attention(att_method, hidden_size)\n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input, last_hidden, encoder_outputs):\n",
    "        # ojo: input es el batch de los ultimos outputs, no es una secuencia\n",
    "        batch_size = input.size(0)\n",
    "        embs = self.embedding(input)\n",
    "        embs = self.embedding_dropout(embs)\n",
    "        embs = embs.view(1, batch_size, self.hidden_size)\n",
    "\n",
    "        # Se corre la RNN en el input con el ultimo hidden state\n",
    "        rnn_output, hidden = self.rnn(embs, last_hidden)\n",
    "        \n",
    "        # Se calcula la atencion y se aplica a las salidas del encoder\n",
    "        att_weights = self.attention(rnn_output, encoder_outputs)\n",
    "        context = att_weights.bmm(encoder_outputs.transpose(0, 1))\n",
    "        \n",
    "        # Se concatenan los valores de salida de la rnn y el contexto\n",
    "        concat_input = torch.cat((rnn_output.squeeze(0), context.squeeze(1)), 1)\n",
    "        concat_output = F.tanh(self.concat(concat_input))\n",
    "        output = self.out(concat_output)\n",
    "\n",
    "        return output, hidden, att_weights\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_epoch(epoch_desc, epoch_batchs, tf_ratio, gradient_clip=5.0, data_set='train',\n",
    "                tqdm_enable=True):\n",
    "    avg_mom = 0.9\n",
    "    avg_loss = 0.0\n",
    "    debias_loss = 0.0\n",
    "    \n",
    "    if data_set == 'train':\n",
    "        encoder.train(True)\n",
    "        decoder.train(True)\n",
    "    else:\n",
    "        encoder.train(False)\n",
    "        decoder.train(False)\n",
    "    \n",
    "    if not tqdm_enable:\n",
    "        range_fun = range(epoch_batchs)\n",
    "    elif data_set == 'train':\n",
    "        range_fun = tnrange(epoch_batchs, desc=epoch_desc)\n",
    "    else:\n",
    "        range_fun = tnrange(epoch_batchs, desc=epoch_desc, leave=False)\n",
    "    \n",
    "    for it in range_fun:\n",
    "        if tqdm_enable:\n",
    "            range_fun.set_postfix(loss=debias_loss, teacher_forcing=tf_ratio)\n",
    "        \n",
    "        # Inicializar gradientes y perdida\n",
    "        if data_set == 'train':\n",
    "            encoder_optimizer.zero_grad()\n",
    "            decoder_optimizer.zero_grad()\n",
    "            \n",
    "        # Obtener batch de entrenamiento\n",
    "#         ### debug gpu memory\n",
    "#         for _ in range(5000):\n",
    "#             training_batch = next(train_iter)\n",
    "#             if training_batch.en.size(0) > 22:\n",
    "#                 break\n",
    "#         ### debug gpu memory\n",
    "        if data_set == 'train':\n",
    "            training_batch = next(train_iter)\n",
    "        elif data_set == 'test':\n",
    "            training_batch = next(test_iter)\n",
    "        elif data_set == 'validation':\n",
    "            training_batch = next(val_iter)\n",
    "            \n",
    "        input_variable = training_batch.es\n",
    "        target_variable = training_batch.en\n",
    "        input_length, batch_size  = input_variable.size()\n",
    "        target_length = target_variable.size()[0]\n",
    "\n",
    "        # Encodear el input\n",
    "        encoder_outputs, encoder_hidden = encoder(input_variable, None)\n",
    "\n",
    "        # Crear variables para el input y output del decoder\n",
    "        decoder_input = Variable(torch.LongTensor([SOS_token] * batch_size)).cuda()\n",
    "        # Fix, las ultimas capas en caso de bidireccional\n",
    "        decoder_hidden = encoder_hidden[-decoder.n_layers:]\n",
    "        all_decoder_outputs = Variable(torch.zeros(\n",
    "            target_length, batch_size, decoder.output_size)).cuda()\n",
    "\n",
    "        # Se ejecuta el decoder en cada paso de la secuencia\n",
    "        for t in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_att = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "\n",
    "            all_decoder_outputs[t] = decoder_output\n",
    "\n",
    "            if t < target_length-1:\n",
    "                # Usar teacher_forcing\n",
    "                use_tf = random.random() < tf_ratio\n",
    "                if use_tf:\n",
    "                    # De la data\n",
    "                    decoder_input = target_variable[t+1]\n",
    "                else:\n",
    "                    # Del modelo\n",
    "                    decoder_input = decoder_output.topk(1, 1)[1]\n",
    "\n",
    "        # Funcion de perdida\n",
    "        log_probs = F.log_softmax(all_decoder_outputs.view(-1, decoder.output_size))\n",
    "        loss = nn.NLLLoss()(log_probs, target_variable.view(-1))\n",
    "        avg_loss = avg_loss * avg_mom + loss.data[0] * (1-avg_mom)\n",
    "        debias_loss = avg_loss / (1 - avg_mom**(it+1))\n",
    "        \n",
    "        # Optimizar parametros\n",
    "        if data_set == 'train':\n",
    "#             ### debug gpu memory\n",
    "#             print(input_length, target_length, avg_loss, loss.data[0], debias_loss)\n",
    "#             try:\n",
    "#                 loss.backward()\n",
    "#             except RuntimeError:\n",
    "#                 import pdb; pdb.set_trace()\n",
    "#             ### debug gpu memory\n",
    "                \n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm(encoder.parameters(), gradient_clip)\n",
    "            nn.utils.clip_grad_norm(decoder.parameters(), gradient_clip)\n",
    "            encoder_scheduler.step()\n",
    "            decoder_scheduler.step()\n",
    "    \n",
    "    return avg_loss if it > 100 else debias_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(batch, max_target_length=train_max_length):\n",
    "    input_length, batch_size  = batch.size()\n",
    "    target_length = min(train_max_length, input_length*2)\n",
    "    eos_check = torch.LongTensor([EOS_token] * batch_size).cuda()\n",
    "    out = []\n",
    "    \n",
    "    # Encodear el input\n",
    "    encoder_outputs, encoder_hidden = encoder(batch, None)\n",
    "\n",
    "    # Crear variables para el input y output del decoder\n",
    "    decoder_input = Variable(torch.LongTensor([SOS_token] * batch_size)).cuda()\n",
    "    # Fix, las ultimas capas en caso de bidireccional\n",
    "    decoder_hidden = encoder_hidden[-decoder.n_layers:]\n",
    "\n",
    "    # Se ejecuta el decoder en cada paso de la secuencia\n",
    "    for t in range(target_length):\n",
    "        decoder_output, decoder_hidden, decoder_att = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs\n",
    "        )\n",
    "\n",
    "        if t < target_length-1:\n",
    "            decoder_input = decoder_output.topk(1, 1)[1]\n",
    "            out.append(decoder_input)\n",
    "\n",
    "        if torch.sum(decoder_input.data.squeeze() == eos_check) == batch_size:\n",
    "            break\n",
    "                \n",
    "    return torch.cat(out, 1).transpose(0, 1).data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "perplexity = lambda x: math.exp(float(x)) if x < 300 else float(\"inf\")\n",
    "\n",
    "def train(epochs, model_name, tf_ratio=1.0, tf_epoch_end=0, results_each=5,\n",
    "          n_examples=3, save_each=5, epoch_batchs_test=10, gradient_clip=5.0):\n",
    "    t0 = time()\n",
    "    results = {}\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    zeros = int(math.log10(epochs)) + 1\n",
    "    \n",
    "    # teacher forcing interpolation\n",
    "    tf = np.zeros(epochs)\n",
    "    tf[:tf_epoch_end] = np.linspace(tf_ratio, 0, tf_epoch_end)\n",
    "    \n",
    "    try:\n",
    "        for i in tnrange(epochs, desc='Training'):\n",
    "            # Entrenar una epoca\n",
    "            l = train_epoch(f'Epoch {i+1:0{zeros}}', epoch_batchs_train,\n",
    "                            tf[i], gradient_clip)\n",
    "            train_loss.append(l)\n",
    "\n",
    "            # Evaluar perdida en el test set (sin teacher forcing)\n",
    "            l = train_epoch(f'Test Loss', epoch_batchs_test,\n",
    "                            0, gradient_clip, data_set='test')\n",
    "            test_loss.append(l)\n",
    "\n",
    "            # Guardar modelo\n",
    "            if (i+1) % save_each == 0:\n",
    "                torch.save(encoder.state_dict(), f'data/{model_name}_encoder.pkl')\n",
    "                torch.save(decoder.state_dict(), f'data/{model_name}_decoder.pkl')\n",
    "\n",
    "            # Mostrar resultados\n",
    "            if (i+1) % results_each == 0:\n",
    "                print('Teacher forcing ratio=%.2f' % tf[i])\n",
    "                print('Train loss=%.5f, perplexity=%.5f' %\n",
    "                      (train_loss[-1], perplexity(train_loss[-1])))\n",
    "                print('Test  loss=%.5f, perplexity=%.5f\\n' %\n",
    "                      (test_loss[-1], perplexity(test_loss[-1])))\n",
    "\n",
    "                # Ejemplos de traduccion\n",
    "                examples = next(train_iter)\n",
    "                examples_es = examples.es[:,:n_examples]\n",
    "                examples_en = examples.en[:,:n_examples].data.cpu().numpy()\n",
    "                predicted = predict(examples_es)\n",
    "                examples_es = examples_es.data.cpu().numpy()\n",
    "                for j in range(n_examples):\n",
    "                    print(' '.join([es_dict[w] for w in examples_es[:, j]]))\n",
    "                    print('Result -> ', ' '.join([en_dict[w] for w in predicted[:, j]]))\n",
    "                    print('Target -> ', ' '.join([en_dict[w] for w in examples_en[:, j]]), '\\n')\n",
    "        \n",
    "            write_training_log(f'data/{model_name}_log.txt', i,\n",
    "                               tf[i], train_loss[-1], test_loss[-1])\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print('Interrupted at epoch: %d' % (i+1))\n",
    "        \n",
    "    results['train_loss'] = train_loss\n",
    "    results['test_loss'] = test_loss\n",
    "        \n",
    "    torch.save(encoder.state_dict(), f'data/{model_name}_encoder.pkl')\n",
    "    torch.save(decoder.state_dict(), f'data/{model_name}_decoder.pkl')\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definir el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderRNN (\n",
      "  (embedding): Embedding(10264, 50)\n",
      "  (embedding_dropout): Dropout (p = 0.1)\n",
      "  (lineal): Linear (50 -> 300)\n",
      "  (rnn): GRU(300, 300, num_layers=2, dropout=0.1, bidirectional=True)\n",
      ")\n",
      "AttnDecoderRNN (\n",
      "  (embedding): Embedding(6548, 300)\n",
      "  (embedding_dropout): Dropout (p = 0.1)\n",
      "  (rnn): GRU(300, 300, num_layers=2, dropout=0.1)\n",
      "  (attention): Attention (\n",
      "    (att): Linear (300 -> 300)\n",
      "  )\n",
      "  (concat): Linear (600 -> 300)\n",
      "  (out): Linear (300 -> 6548)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_name = 'seq2seq'\n",
    "encoder_hidden = 300 # Tamaño de los vectores GloVe\n",
    "encoder_bi = True\n",
    "n_layers = 2\n",
    "lr = 0.001\n",
    "teacher_forcing_epoch_end = 5\n",
    "epochs = 10\n",
    "\n",
    "encoder = EncoderRNN(len(ES.vocab.itos), encoder_hidden, n_layers, bidirectional=encoder_bi).cuda()\n",
    "decoder = AttnDecoderRNN(len(EN.vocab.itos), encoder_hidden, n_layers).cuda()\n",
    "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=lr)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
    "encoder_scheduler, decoder_scheduler = encoder_optimizer, decoder_optimizer\n",
    "print(encoder); print(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Cargar pesos\n",
    "# encoder.load_state_dict(torch.load(f'data/{model_name}_encoder.pkl'))\n",
    "# decoder.load_state_dict(torch.load(f'data/{model_name}_decoder.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l = train_epoch('asd', 500, 0.5, data_set='train')\n",
    "# l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c916b3b09be74d3ea62722e5e398fca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "246f8a2eaa4542c3b29067cfedff4c3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03cb509567fb46caaccb84823378c469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "070b6e10ec574c6f9c77265b51d7080d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f04524e322144eea803d52d7bba8bd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0ecff2570704c41807f1aa8be5848f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99aa09d73c47449e8039fb761f998534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f489020b0ab4c11a265f78b091b4972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58549acdfefa4dcc945a17806cb36bcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2ef97c7bbe84bdd8b86fb71babc2c66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e56185fc6b114114be50686ff468f1e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher forcing ratio=0.00\n",
      "Train loss=4.73445, perplexity=113.80138\n",
      "Test  loss=4.31420, perplexity=74.75347\n",
      "\n",
      "baja la voz .\n",
      "Result ->  <sos> tom . . . . .\n",
      "Target ->  <sos> lower your voice . <eos> \n",
      "\n",
      "él la abrazó .\n",
      "Result ->  <sos> tom . . . . .\n",
      "Target ->  <sos> he hugged her . <eos> \n",
      "\n",
      "tira los dados .\n",
      "Result ->  <sos> tom . . . . .\n",
      "Target ->  <sos> throw the dice . <eos> \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5330fe71cf2149e3af07a23d8da3174c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fd9388df34f4743a2331ee58ac694ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccb11e3d5b0544b2920790451d964ae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55f0d8eb3e444e2a99aa9a39e579fd28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2034e4bc26f94ffe946045ab6df91c85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9340f56042ff472887dec306e523fbfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17a1674df85549cf90a457d1e609acfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6aea4a5eb024372b7726b17dc16e4df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0e371a6123d4d2fb0208d494325b3b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9732e026112243fc914a0b126cedbf6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher forcing ratio=0.00\n",
      "Train loss=4.55582, perplexity=95.18448\n",
      "Test  loss=4.83032, perplexity=125.25068\n",
      "\n",
      "no he visto ni oído nada .\n",
      "Result ->  <sos> i you . . . <eos>\n",
      "Target ->  <sos> i neither heard nor saw anything . <eos> \n",
      "\n",
      "siempre me levanto a las 6 .\n",
      "Result ->  <sos> i you . . . <eos>\n",
      "Target ->  <sos> i always get up at six . <eos> \n",
      "\n",
      "jugamos a muchas clases de juegos .\n",
      "Result ->  <sos> i you . . . <eos>\n",
      "Target ->  <sos> we played many kinds of games . <eos> \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "epoch_batchs_train = 10\n",
    "results = train(10, model_name+'_test', tf_epoch_end=5, results_each=5, epoch_batchs_test=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsYAAAD8CAYAAAB0FmJXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f79edb4b3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(results['train_loss'], label='train')\n",
    "plt.plot(results['test_loss'], label='test')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# results = train(epochs, teacher_forcing_epoch_end, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12,4))\n",
    "# plt.plot(results['train_loss'], label='train')\n",
    "# plt.plot(results['test_loss'], label='test')\n",
    "# plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ver resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nadie lo sabía . <pad> <pad>\n",
      "Result ->  <sos> i i . . . . <eos>\n",
      "Target ->  <sos> nobody knew . <eos> <pad> \n",
      "\n",
      "me quedé dormido . <pad> <pad>\n",
      "Result ->  <sos> i is . . . . <eos>\n",
      "Target ->  <sos> i overslept . <eos> <pad> \n",
      "\n",
      "<unk> a tomás . <pad> <pad>\n",
      "Result ->  <sos> i is . . . . <eos>\n",
      "Target ->  <sos> follow tom . <eos> <pad> \n",
      "\n",
      "no te muevas . <pad> <pad>\n",
      "Result ->  <sos> i i the . . . <eos>\n",
      "Target ->  <sos> be still . <eos> <pad> \n",
      "\n",
      "¿ quién escuchó ? <pad> <pad>\n",
      "Result ->  <sos> i you you ? ? <eos> <eos>\n",
      "Target ->  <sos> who listened ? <eos> <pad> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_examples = 5\n",
    "examples = next(train_iter)\n",
    "examples_es = examples.es[:,:n_examples]\n",
    "examples_en = examples.en[:,:n_examples].data.cpu().numpy()\n",
    "predicted = predict(examples_es)\n",
    "examples_es = examples_es.data.cpu().numpy()\n",
    "for i in range(n_examples):\n",
    "    print(' '.join([es_dict[w] for w in examples_es[:, i]]))\n",
    "    print('Result -> ', ' '.join([en_dict[w] for w in predicted[:, i]]))\n",
    "    print('Target -> ', ' '.join([en_dict[w] for w in examples_en[:, i]]), '\\n')\n",
    "    # TODO: plot attention"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
